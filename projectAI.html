<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <title>Robot project</title>
      <link rel="stylesheet" href="styleAbout.css">
   </head>
   <body>
      <a href="#main" class="skip-link">Skip to main content</a>
      <header>
         <div class="container">
            <div class="header_wrapper">
               <h1>Brian Kloosterman Jr.</h1>
               <nav aria-label="Main navigation">
                  <ul>
                     <li><a href="index.html">Works</a></li>
                     <li><a href="about.html">About</a></li>
                  </ul>
               </nav>
            </div>
         </div>
      </header>
      <main id="main">
         <div class="container">
            <div class="about_main">
               <h2>Autonomous Robot with Full-Stack Control Platform</h2>
               <p><strong>In early 2023, after playing with LLMs, I realized that if I could translate reality into a text adventure, I could create a fully autonomous droid like the ones from the sci-fi books and films I grew up with.</strong></p>

               <h3>ThirdPerson AI Platform (2024)</h3>
               <p>The latest iteration features a production-ready web control system deployed on Railway with PostgreSQL backend. This comprehensive platform integrates multiple AI modalities into a unified control interface:</p>

               <h4>Core Capabilities</h4>
               <ul>
                  <li>ğŸ¤– <strong>Multi-Model LLM Integration:</strong> Real-time chat with Llama 3.1 (8B, 70B, 405B) via Together.ai API with streaming responses</li>
                  <li>ğŸ‘ï¸ <strong>Computer Vision:</strong> YOLOv8 object recognition with TensorFlow.js, real-time camera analysis, stereo depth perception</li>
                  <li>ğŸ—£ï¸ <strong>Audio Processing:</strong> Bidirectional speech (Whisper STT + multiple TTS voices), voice-activated commands</li>
                  <li>ğŸ“¡ <strong>LIDAR Spatial Mapping:</strong> Real-time environmental scanning with Python integration, live browser visualization</li>
                  <li>ğŸ§  <strong>Persistent Memory System:</strong> Working and long-term memory with categorization, importance scoring, and retrieval</li>
                  <li>ğŸ® <strong>Robot Control Interface:</strong> Autonomous/manual modes, Arduino serial communication, wake/sleep/reset commands</li>
                  <li>ğŸ” <strong>Full Authentication:</strong> JWT-based user system, secure API key management, multi-user support</li>
               </ul>

               <h4>Technical Architecture</h4>
               <ul>
                  <li>ğŸ’» <strong>Backend:</strong> Node.js/Express with PostgreSQL, RESTful API, WebSocket streaming</li>
                  <li>ğŸ¨ <strong>Frontend:</strong> Vanilla JavaScript, responsive design, real-time updates</li>
                  <li>ğŸš€ <strong>Deployment:</strong> Railway platform with continuous deployment, environment management</li>
                  <li>ğŸ”§ <strong>Hardware Interface:</strong> Python LIDAR integration, Arduino serial control, multi-sensor fusion</li>
               </ul>

               <p><em>Note: A significant portion of this platform was "vibe coded" - rapidly prototyped through exploratory development and AI-assisted coding, demonstrating ability to quickly ship complex full-stack applications.</em></p>

               <h4>Evolution & Future Enhancements</h4>
               <p>This is part of the first wave of AI bots that stitch together disparate technologies to create bots that are mostly playthings for early adopters. The first companies to get enough of these on the market and collect enough data will be able to train more multimodal models native to an embodied form and explore and manipulate reality.
                As it stands, the additional goals and features that I see in this generation are as follows:</p>
               <ul>
                  <li>ğŸ‘¤ Advanced person/object recognition with persistent identity tracking</li>
                  <li>ğŸš§ Enhanced obstacle avoidance and pathfinding algorithms</li>
                  <li>ğŸ˜ŠğŸ˜¢ Emotion recognition and responsive behavior</li>
                  <li>ğŸ§º Manipulator arm integration for object interaction</li>
                  <li>ğŸŒ Web service integration and API access for information retrieval</li>
                  <li>ğŸ—£ Expressive TTS with emotional inflection and facial animation</li>
               </ul>
               <div class="project_content">
                     <div class="project_up">
                      <a href="projects/robot/me.jpg" target="_blank">
                        <img src="projects/robot/me.jpg" alt="Me working on robot.">
                        </a>
                        <div class="video_project">
                          <video controls>
                            <source src="projects/robot/h2.mp4" type="video/mp4">
                         </video>
                         <video controls>
                          <source src="projects/robot/h3.mp4" type="video/mp4">
                       </video>
                       <a href="projects/robot/interface.jpg" target="_blank">
                        <img style="max-width: 500px; width: 100%;" src="projects/robot/interface.jpg" alt="Using its interface">
                        </a>
                        </div>
                     </div>
               </div>
               <div class="links">
                  <h2>Links & Resources</h2>
                  <ul>
                     <li><a href="https://accurate-laughter-production.up.railway.app/robot" target="_blank"><strong>ğŸ”´ LIVE: ThirdPerson AI Platform</strong></a> - Production deployment on Railway with full robot control interface</li>
                     <li><a href="https://github.com/theluckyfellow/BotTab" target="_blank">GitHub: Legacy OpenAI Version</a> - Original robotic implementation using OpenAI's API</li>
                     <li><a href="https://vcrtapes.s3.ap-southeast-1.amazonaws.com/robotTab/index.html" target="_blank">Demo: Together.ai Prototype</a> - Earlier non-robotic version demonstrating API integration</li>
                  </ul>
                  <p><em>Repository for current ThirdPerson platform available upon request.</em></p>
               </div>
            </div>
         </div>
      </main>
   </body>
</html>