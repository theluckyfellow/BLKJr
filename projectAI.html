<!DOCTYPE html>
    <html lang="en">

    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <title>Robot project</title>
        <link rel="stylesheet" href="style.css">
    </head>

    <body>
      <header>
        <h1>Brian Kloosterman Jr.</h1>
        <nav>
          <ul>
            <li><a href="index.html">Works</a></li>
            <li><a href="about.html">About</a></li>
          </ul>
        </nav>
      </header>
        <main>
            <h1>Synthet</h1>
            <p><h4>In early 2023, after playing with LLMs, I realized that if I could translate reality into a text adventure, I could create a fully autonomous droid like the ones from the sci-fi books and films I grew up with.</h4>
              This is a fully autonomous LLM-driven bot. It has enhanced features like:
              <ul>
                  <li>👁️‍🗨️Object recognitions with Tensorflow.js (YoloV8s)</li>
                  <li>👀Stereo vision for depth perception</li>
                  <li>🚶‍♂️Ability to move and explore on its own</li>
                  <li>🔌Using a serial connection to an Arduino board</li>
                  <li>🧠Longterm and working memory system</li>
                  <li>🧠Ability to edit its system commands to keep awareness of current task</li>
                  <li>💾Ability to record, update, and remove long-term memories in a simple database</li>
                  <li>🗣Ability to listen and speak using Whisper + Google TTS</li>

              </ul>
              This is part of the first wave of AI bots that stitch together disparate technologies to create bots that are mostly playthings for early adopters. The first companies to get enough of these on the market and collect enough data will be able to train more multimodal models native to an embodied form and explore and manipulate reality.
              As it stands, the additional goals and features that I see in this generation are as follows:
              <ul>

                  <li>👤Ability to learn specific people and objects</li>
                  <li>🚧Ability to recognize obstacles and walls</li>
                  <li>😊😢Ability to recognize emotions</li>
                  <li>🧺Ability to pick up and carry objects</li>
                  <li>🌐Ability to access the web and other services</li>
                  <li>🗣Ability to use facial expressions and vocal inflection with a better TTS</li>
                
              
              </ul>
            </p>

            <div class="project-content">
                <div class="images">
                    <a href="projects/robot/me.jpg" target="_blank">
                        <img src="projects/robot/me.jpg" alt="Me working on robot.">
                    </a>
                    <video controls>
                      <source src="projects/robot/h2.mp4" type="video/mp4">
                  </video>
                    <a href="projects/robot/interface.jpg" target="_blank">
                        <img src="projects/robot/interface.jpg" alt="Using its interface">
                    </a>

              
                  <video controls>
                      <source src="projects/robot/h3.mp4" type="video/mp4">
                  </video>
              
                </div>
              </div>
                <div class="links">
                    <h2>Links</h2>
                    <ul>
                        <li>*(coming soon) Link to full new together.ai robotic version</li>
                        <li><a href="https://vcrtapes.s3.ap-southeast-1.amazonaws.com/robotTab/index.html" target="_blank">*New non-robitic version that makes use of together.ai API and my own servers</a></li>
                        <li><a href="https://github.com/theluckyfellow/BotTab" target="_blank">*Old robotic version which made use of OpenAI's API</a></li>
                    </ul>
                
            </div>
        </main>
    </body>

    </html>